{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw5pr2digits:  digits clasification via decision trees and random forests...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's use the data to create \"more informed\" models\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic.csv : file read into a pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "# let's read in our flower data...\n",
    "# \n",
    "# for read_csv, use header=0 when row 0 is a header row\n",
    "# \n",
    "filename = 'titanic.csv'\n",
    "df = pd.read_csv(filename, header=0)   # encoding=\"latin1\" et al.\n",
    "print(f\"{filename} : file read into a pandas dataframe.\")\n",
    "\n",
    "# [[ for hw5pr1's conversion:  the new file will be needed here ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>the original Kaggle dataset!   Adapted from here:   https://www.kaggle.com/c/titanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                             name  \\\n",
       "0          1         1                    Allen, Miss. Elisabeth Walton   \n",
       "1          1         1                   Allison, Master. Hudson Trevor   \n",
       "2          1         0                     Allison, Miss. Helen Loraine   \n",
       "3          1         0             Allison, Mr. Hudson Joshua Creighton   \n",
       "4          1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "...      ...       ...                                              ...   \n",
       "1262       3         0                             Zabour, Miss. Hileni   \n",
       "1263       3         0                            Zabour, Miss. Thamine   \n",
       "1264       3         0                        Zakarian, Mr. Mapriededer   \n",
       "1265       3         0                              Zakarian, Mr. Ortin   \n",
       "1266       3         0                               Zimmerman, Mr. Leo   \n",
       "\n",
       "         sex      age  sibsp  parch  ticket      fare    cabin embarked boat  \\\n",
       "0     female  29.0000      0      0   24160  211.3375       B5        S    2   \n",
       "1       male   0.9167      1      2  113781  151.5500  C22 C26        S   11   \n",
       "2     female   2.0000      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "3       male  30.0000      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "4     female  25.0000      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "...      ...      ...    ...    ...     ...       ...      ...      ...  ...   \n",
       "1262  female  14.5000      1      0    2665   14.4542      NaN        C  NaN   \n",
       "1263  female      NaN      1      0    2665   14.4542      NaN        C  NaN   \n",
       "1264    male  26.5000      0      0    2656    7.2250      NaN        C  NaN   \n",
       "1265    male  27.0000      0      0    2670    7.2250      NaN        C  NaN   \n",
       "1266    male  29.0000      0      0  315082    7.8750      NaN        S  NaN   \n",
       "\n",
       "       body                        home.dest  \\\n",
       "0       NaN                     St Louis, MO   \n",
       "1       NaN  Montreal, PQ / Chesterville, ON   \n",
       "2       NaN  Montreal, PQ / Chesterville, ON   \n",
       "3     135.0  Montreal, PQ / Chesterville, ON   \n",
       "4       NaN  Montreal, PQ / Chesterville, ON   \n",
       "...     ...                              ...   \n",
       "1262  328.0                              NaN   \n",
       "1263    NaN                              NaN   \n",
       "1264  304.0                              NaN   \n",
       "1265    NaN                              NaN   \n",
       "1266    NaN                              NaN   \n",
       "\n",
       "      the original Kaggle dataset!   Adapted from here:   https://www.kaggle.com/c/titanic  \n",
       "0                                                   NaN                                     \n",
       "1                                                   NaN                                     \n",
       "2                                                   NaN                                     \n",
       "3                                                   NaN                                     \n",
       "4                                                   NaN                                     \n",
       "...                                                 ...                                     \n",
       "1262                                                NaN                                     \n",
       "1263                                                NaN                                     \n",
       "1264                                                NaN                                     \n",
       "1265                                                NaN                                     \n",
       "1266                                                NaN                                     \n",
       "\n",
       "[1267 rows x 15 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# a dataframe is a \"spreadsheet in Python\"   (seems to have an extra column!)\n",
    "#\n",
    "pd.set_option('display.max_rows', 10)     # None for no limit; default: 10\n",
    "# pd.set_option('display.min_rows', 150)   # min_rows is not universally supported...\n",
    "# let's view it!\n",
    "df\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed here ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1267 entries, 0 to 1266\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                --------------  -----  \n",
      " 0   pclass                                                                                1267 non-null   int64  \n",
      " 1   survived                                                                              1267 non-null   int64  \n",
      " 2   name                                                                                  1267 non-null   object \n",
      " 3   sex                                                                                   1267 non-null   object \n",
      " 4   age                                                                                   1004 non-null   float64\n",
      " 5   sibsp                                                                                 1267 non-null   int64  \n",
      " 6   parch                                                                                 1267 non-null   int64  \n",
      " 7   ticket                                                                                1267 non-null   object \n",
      " 8   fare                                                                                  1266 non-null   float64\n",
      " 9   cabin                                                                                 278 non-null    object \n",
      " 10  embarked                                                                              1265 non-null   object \n",
      " 11  boat                                                                                  465 non-null    object \n",
      " 12  body                                                                                  116 non-null    float64\n",
      " 13  home.dest                                                                             706 non-null    object \n",
      " 14  the original Kaggle dataset!   Adapted from here:   https://www.kaggle.com/c/titanic  0 non-null      float64\n",
      "dtypes: float64(4), int64(4), object(7)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's look at our pandas dataframe   (Aargh: that extra column!)\n",
    "#\n",
    "df.info()\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed here ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1267 entries, 0 to 1266\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1267 non-null   int64  \n",
      " 1   survived  1267 non-null   int64  \n",
      " 2   sex       1267 non-null   object \n",
      " 3   age       1004 non-null   float64\n",
      " 4   sibsp     1267 non-null   int64  \n",
      " 5   parch     1267 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 59.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch\n",
       "0       1         1  female  29.0000      0      0\n",
       "1       1         1    male   0.9167      1      2\n",
       "2       1         0  female   2.0000      1      2\n",
       "3       1         0    male  30.0000      1      2\n",
       "4       1         0  female  25.0000      1      2"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# ok!  let's drop columns that are\n",
    "#      + \"cheating\"  (they give away the answer and wouldn't be available)\n",
    "#      + too sparse  (too many NAs)\n",
    "#\n",
    "\n",
    "\n",
    "# the \"boat\" column is present when the lifeboat number is known: too much info!\n",
    "df_2 = df.drop('boat', axis=1)     # or, axis = 1 indicates we want to drop a column, not a row\n",
    "\n",
    "# the \"cabin\" column has too many missing values...\n",
    "df_2 = df_2.drop('cabin', axis=1)\n",
    "\n",
    "df_2 = df_2.drop('body', axis=1) \n",
    "df_2 = df_2.drop('fare', axis=1)\n",
    "df_2 = df_2.drop('ticket', axis=1)\n",
    "df_2 = df_2.drop('name', axis=1)\n",
    "df_2 = df_2.drop('home.dest', axis=1)\n",
    "df_clean = df_2.drop('embarked', axis=1)\n",
    "\n",
    "COLUMNS = df_clean.columns    \n",
    "last_column = COLUMNS[-1]  # don't want the \"url\" column...\n",
    "\n",
    "df_clean = df_clean.drop(columns=[last_column])  # drop by name is ok\n",
    "\n",
    "# let's see what's there...\n",
    "df_clean.info()  # re-look at the data ...    \n",
    "# + some will still have too many NA's!\n",
    "# + some will still be \"cheating\"\n",
    "# + some simply won't be worth having\n",
    "\n",
    "df_clean.head()\n",
    "\n",
    "# [[ for hw5pr1's conversion:  there's a different column to drop... ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# # let's keep our column names in variables, for reference\n",
    "# #\n",
    "# COLUMNS = df_clean.columns            # \"list\" of columns\n",
    "# print(f\"COLUMNS is {COLUMNS}\\n\")  \n",
    "#   # It's a \"pandas\" list, called an Index\n",
    "#   # use it just as a Python list of strings:\n",
    "# print(f\"COLUMNS[0] is {COLUMNS[0]}\\n\")\n",
    "\n",
    "# # let's create a dictionary to look up any column index by name\n",
    "# COL_INDEX = {}\n",
    "# for i, name in enumerate(COLUMNS):\n",
    "#     COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "# print(f\"COL_INDEX is {COL_INDEX}\")\n",
    "\n",
    "# # [[ for hw5pr1's conversion:  no changes needed here ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1267 entries, 0 to 1266\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1267 non-null   int64  \n",
      " 1   survived  1267 non-null   int64  \n",
      " 2   sex       1267 non-null   object \n",
      " 3   age       1004 non-null   float64\n",
      " 4   sibsp     1267 non-null   int64  \n",
      " 5   parch     1267 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 59.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived     sex      age  sibsp  parch\n",
       "0          1         1  female  29.0000      0      0\n",
       "1          1         1    male   0.9167      1      2\n",
       "2          1         0  female   2.0000      1      2\n",
       "3          1         0    male  30.0000      1      2\n",
       "4          1         0  female  25.0000      1      2\n",
       "...      ...       ...     ...      ...    ...    ...\n",
       "1262       3         0  female  14.5000      1      0\n",
       "1263       3         0  female      NaN      1      0\n",
       "1264       3         0    male  26.5000      0      0\n",
       "1265       3         0    male  27.0000      0      0\n",
       "1266       3         0    male  29.0000      0      0\n",
       "\n",
       "[1267 rows x 6 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's look at our cleaned-up dataframe...\n",
    "#\n",
    "df_clean.info()   \n",
    "#\n",
    "# notice that the non-null is _different_ for irisname!\n",
    "df_clean   # show a table! (the problem rows are the last two...)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed here ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1266\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1004 non-null   int64  \n",
      " 1   survived  1004 non-null   int64  \n",
      " 2   sex       1004 non-null   object \n",
      " 3   age       1004 non-null   float64\n",
      " 4   sibsp     1004 non-null   int64  \n",
      " 5   parch     1004 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 54.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived     sex      age  sibsp  parch\n",
       "0          1         1  female  29.0000      0      0\n",
       "1          1         1    male   0.9167      1      2\n",
       "2          1         0  female   2.0000      1      2\n",
       "3          1         0    male  30.0000      1      2\n",
       "4          1         0  female  25.0000      1      2\n",
       "...      ...       ...     ...      ...    ...    ...\n",
       "1259       3         0    male  45.5000      0      0\n",
       "1262       3         0  female  14.5000      1      0\n",
       "1264       3         0    male  26.5000      0      0\n",
       "1265       3         0    male  27.0000      0      0\n",
       "1266       3         0    male  29.0000      0      0\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# typically, after dropping columns we don't want, \n",
    "#   we drop rows with missing data (other approaches are possible, too)\n",
    "#\n",
    "df_full = df_clean.dropna()   # this removes all rows with missing data (\"na\")\n",
    "df_full.info()                # it's \"full\" because it has no missing data\n",
    "df_full\n",
    "#\n",
    "# notice that _all_ of the rows now have 142 non-null items\n",
    "#    also, the last row isn't real data... we'll handle it next\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed here ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# get rid of last row!\n",
    "#\n",
    "# df_final = df_full.iloc[0:-1]     # not the syntax I would choose\n",
    "# print(df_final.shape)\n",
    "# df_final\n",
    "\n",
    "# [[ for hw5pr1's conversion:  many \"wrong\" rows are scattered throughout births.csv;\n",
    "#     however, it's totally ok to keep them for hw5pr1's purposes! (up to you) ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-173-ea95774fcd04>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['sex'] = df_full['sex'].apply(numberize)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# everything needs to be numeric! we'll convert female/male to 1/0\n",
    "#\n",
    "\n",
    "def numberize(s):\n",
    "    \"\"\" converts 'male'/'female' to 0/1 \"\"\"\n",
    "    if s == 'female': return 1\n",
    "    else:  return 0                   # or return int(s=='female')\n",
    "\n",
    "df_full['sex'] = df_full['sex'].apply(numberize)\n",
    "\n",
    "# can't run this cell twice!   (we've replaced things!)\n",
    "    \n",
    "# [[ for hw5pr1's conversion:  it's good to have SPECIES!\n",
    "#      This will need updating for the \"above median\" and \"below median\" species ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# we can \"apply\" a function to a whole column\n",
    "#   it may give a warning; here, this is ok ...\n",
    "#\n",
    "\n",
    "# df_final['number'] = df_final['number'].apply(convert_species)\n",
    "\n",
    "# Don't run this twice: the data will be different the second time!\n",
    "#   (In reality, feel free to go back and re-run cells to re-establish things... :-)\n",
    "#    Don't worry about the (possible)  \"SettingWithCopyWarning\" here...\n",
    "\n",
    "# [[ for hw5pr1's conversion:  you may or may not need this... ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's see it!  (this is safe to run many times...)\n",
    "\n",
    "# print(df_final.to_string())  # for _all_ rows...\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS is Index(['pclass', 'sex', 'age', 'sibsp', 'parch'], dtype='object')\n",
      "\n",
      "COLUMNS[0] is pclass\n",
      "\n",
      "COL_INDEX is {'pclass': 0, 'sex': 1, 'age': 2, 'sibsp': 3, 'parch': 4}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's keep our column names in variables, for reference\n",
    "#\n",
    "df_xOnly = df_full.drop('survived', axis=1)\n",
    "COLUMNS = df_xOnly.columns          # \"list\" of feature columns. Does not include survived\n",
    "\n",
    "print(f\"COLUMNS is {COLUMNS}\\n\")  \n",
    "  # It's a \"pandas\" list, called an Index\n",
    "  # use it just as a Python list of strings:\n",
    "print(f\"COLUMNS[0] is {COLUMNS[0]}\\n\")\n",
    "\n",
    "# let's create a dictionary to look up any column index by name\n",
    "COL_INDEX = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "print(f\"COL_INDEX is {COL_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is [[ 1.      1.      1.     29.      0.      0.    ]\n",
      " [ 1.      1.      0.      0.9167  1.      2.    ]\n",
      " [ 1.      0.      1.      2.      1.      2.    ]\n",
      " ...\n",
      " [ 3.      0.      0.     26.5     0.      0.    ]\n",
      " [ 3.      0.      0.     27.      0.      0.    ]\n",
      " [ 3.      0.      0.     29.      0.      0.    ]]\n",
      "\n",
      "The dataset has 1004 rows and 6 cols\n",
      "+++ Start of data definitions +++\n",
      "\n",
      "x_all (just features) is \n",
      " [[ 1.      1.     29.      0.      0.    ]\n",
      " [ 1.      0.      0.9167  1.      2.    ]\n",
      " [ 1.      1.      2.      1.      2.    ]\n",
      " ...\n",
      " [ 3.      0.     26.5     0.      0.    ]\n",
      " [ 3.      0.     27.      0.      0.    ]\n",
      " [ 3.      0.     29.      0.      0.    ]]\n",
      "y_all (just labels)   is \n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      "[[ 1.      1.      1.     29.      0.      0.    ]\n",
      " [ 1.      1.      0.      0.9167  1.      2.    ]\n",
      " [ 1.      0.      1.      2.      1.      2.    ]\n",
      " ...\n",
      " [ 3.      0.      0.     26.5     0.      0.    ]\n",
      " [ 3.      0.      0.     27.      0.      0.    ]\n",
      " [ 3.      0.      0.     29.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's convert our dataframe to a numpy array, named A\n",
    "#    Our ML library, scikit-learn operates entirely on numpy arrays.\n",
    "#\n",
    "\n",
    "\n",
    "# Get numpy array version of dataframe \n",
    "A = df_full.values    # .values gets the numpy array\n",
    "A = A.astype('float64')\n",
    "print(f\"A is {A}\")\n",
    "NUM_ROWS, NUM_COLS = A.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")\n",
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "x_all = np.append(A[:,0:1], A[:,2:], 1)  # X (features) \n",
    "y_all = A[:, 1]    # y (labels) \n",
    "\n",
    "print(f\"x_all (just features) is \\n {x_all}\")\n",
    "print(f\"y_all (just labels)   is \\n {y_all}\")\n",
    "\n",
    "print(A)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's make sure it's all floating-point, so we can multiply and divide\n",
    "#\n",
    "# A = A.astype('float64')  # so many:  www.tutorialspoint.com/numpy/numpy_data_types.htm\n",
    "# print(A)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# nice to have NUM_ROWS and NUM_COLS around\n",
    "#\n",
    "# NUM_ROWS, NUM_COLS = A.shape\n",
    "# print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # let's use all of our variables, to reinforce names...\n",
    "\n",
    "# # choose a row index, n:\n",
    "# n = 5\n",
    "# print(f\"row #{n} is {A[n]}\")\n",
    "\n",
    "# for i in range(len(COLUMNS)):\n",
    "#     colname = COLUMNS[i]\n",
    "#     if colname != 'actual_digit':\n",
    "#         print(f\"  Its {colname} is {A[n][i]}\")\n",
    "#     else:\n",
    "#         species_num = int(A[n][i])\n",
    "#         species = NUMBER[species_num]\n",
    "#         print(f\"  Its {colname} is {species} ({species_num})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# we could write-our-own, but we don't have to! Let's \"library\"! After all,\n",
    "#\n",
    "#     the representation and storage for the trees is a big task\n",
    "#     we want an already-debugged algorithm!\n",
    "#     we want to ask q'ns about irises and how \"classifiable\" they are, \n",
    "#        rather than questions about implementation (at least for this moment...)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "# x_all = A[:,0:64]  # X (features) \n",
    "# y_all = A[:,64]    # y (labels) \n",
    "\n",
    "# print(f\"X_all (just features) is \\n {X_all}\")\n",
    "# print(f\"y_all (just labels)   is \\n {y_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# we can re-weight different features here...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.   1.  28.   0.   0. ]\n",
      " [ 3.   0.  17.   1.   0. ]\n",
      " [ 3.   0.  23.   0.   0. ]\n",
      " ...\n",
      " [ 1.   0.  49.   1.   0. ]\n",
      " [ 1.   0.  45.5  0.   0. ]\n",
      " [ 3.   0.  32.   0.   0. ]]\n",
      "[1. 0. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we scramble the data, to give a different TRAIN/TEST split each time...\n",
    "# \n",
    "indices = np.random.permutation(len(y_all))  # indices is a permutation-list\n",
    "\n",
    "# we scramble both X and y, necessarily with the same permutation\n",
    "x_labeled = x_all[indices]              # we apply the _same_ permutation to each!\n",
    "y_labeled = y_all[indices]              # again...\n",
    "print(x_labeled)\n",
    "print(y_labeled)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 804 rows;  testing with 200 rows\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "NUM_ROWS = x_labeled.shape[0]     # the number of labeled rows\n",
    "TEST_PERCENT = 0.20\n",
    "TEST_SIZE = int(TEST_PERCENT*NUM_ROWS)   # no harm in rounding down\n",
    "\n",
    "x_test = x_labeled[:TEST_SIZE]    # first section are for testing\n",
    "y_test = y_labeled[:TEST_SIZE]\n",
    "\n",
    "x_train = x_labeled[TEST_SIZE:]   # all the rest are for training\n",
    "y_train = y_labeled[TEST_SIZE:]\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\" )\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test is [1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "y_train is [1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test is {y_test}\")\n",
    "print(f\"y_train is {y_train}\")   # to \"get a visual\" on these...\n",
    "# print(x_test)\n",
    "# print(x_train)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a DT classifier with max depth = 1\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-building and Model-training Cell\"\n",
    "#       \n",
    "# Create a DT model and train it! \n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "best_depth = 1   # we don't know what depth to use, so we guess...\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model.fit(x_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a DT classifier with max depth =\", best_depth) \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not survived maps to 0\n",
      "survived maps to 1\n"
     ]
    }
   ],
   "source": [
    "SPECIES = ['not survived', 'survived']   # int to str\n",
    "SPECIES_INDEX = {'not survived':0,'survived':1}  # str to int\n",
    "\n",
    "def convert_species(speciesname):\n",
    "    \"\"\" return the species index (a unique integer/category) \"\"\"\n",
    "    #print(f\"converting {speciesname}...\")\n",
    "    return SPECIES_INDEX[speciesname]\n",
    "\n",
    "# Let's try it out...\n",
    "for name in SPECIES:\n",
    "    print(f\"{name} maps to {convert_species(name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function to print testing results in a vertical table (or, an excuse to f-string?)\n",
    "#\n",
    "\n",
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a more neatly formatted comparison \"\"\"\n",
    "    SPECIES_LABELS = len(predicted_labels)\n",
    "    species_correct = 0\n",
    "    \n",
    "    for i in range(SPECIES_LABELS):\n",
    "        p = int(round(predicted_labels[i]))         # round protects from fp error \n",
    "        a = int(round(actual_labels[i]))\n",
    "        result = \"incorrect\"\n",
    "        if p == a:  # if they match,\n",
    "            result = \"\"       # no longer incorrect\n",
    "            species_correct += 1  # and we count a match!\n",
    "        \n",
    "        print(f\"row {i:>3d} : {SPECIES[p]:>12s} {SPECIES[a]:<12s}   {result}\")   \n",
    "\n",
    "    print()\n",
    "    print(\"Correct:\", species_correct, \"out of\", SPECIES_LABELS)\n",
    "    return species_correct\n",
    "\n",
    "# [[ for hw5pr1's conversion:  a _few_ changes needed, \n",
    "#     depending on whether you defined SPECIES and the d/s datatypes ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "Actual  labels  : [1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "\n",
      "Results on test set:  160 correct out of 200 total.\n",
      "row   0 :     survived survived       \n",
      "row   1 : not survived not survived   \n",
      "row   2 : not survived not survived   \n",
      "row   3 :     survived survived       \n",
      "row   4 : not survived not survived   \n",
      "row   5 : not survived not survived   \n",
      "row   6 : not survived survived       incorrect\n",
      "row   7 :     survived survived       \n",
      "row   8 : not survived not survived   \n",
      "row   9 : not survived not survived   \n",
      "row  10 :     survived survived       \n",
      "row  11 :     survived survived       \n",
      "row  12 : not survived not survived   \n",
      "row  13 :     survived not survived   incorrect\n",
      "row  14 : not survived not survived   \n",
      "row  15 :     survived survived       \n",
      "row  16 : not survived not survived   \n",
      "row  17 :     survived survived       \n",
      "row  18 : not survived not survived   \n",
      "row  19 :     survived survived       \n",
      "row  20 : not survived not survived   \n",
      "row  21 : not survived not survived   \n",
      "row  22 : not survived not survived   \n",
      "row  23 :     survived survived       \n",
      "row  24 :     survived survived       \n",
      "row  25 : not survived not survived   \n",
      "row  26 : not survived survived       incorrect\n",
      "row  27 : not survived survived       incorrect\n",
      "row  28 : not survived not survived   \n",
      "row  29 : not survived not survived   \n",
      "row  30 : not survived not survived   \n",
      "row  31 : not survived not survived   \n",
      "row  32 :     survived survived       \n",
      "row  33 :     survived not survived   incorrect\n",
      "row  34 :     survived survived       \n",
      "row  35 :     survived survived       \n",
      "row  36 : not survived not survived   \n",
      "row  37 :     survived survived       \n",
      "row  38 : not survived not survived   \n",
      "row  39 : not survived not survived   \n",
      "row  40 :     survived survived       \n",
      "row  41 :     survived not survived   incorrect\n",
      "row  42 : not survived not survived   \n",
      "row  43 : not survived not survived   \n",
      "row  44 : not survived survived       incorrect\n",
      "row  45 : not survived not survived   \n",
      "row  46 : not survived not survived   \n",
      "row  47 : not survived not survived   \n",
      "row  48 :     survived not survived   incorrect\n",
      "row  49 :     survived survived       \n",
      "row  50 : not survived not survived   \n",
      "row  51 : not survived not survived   \n",
      "row  52 : not survived not survived   \n",
      "row  53 : not survived not survived   \n",
      "row  54 : not survived not survived   \n",
      "row  55 : not survived not survived   \n",
      "row  56 :     survived survived       \n",
      "row  57 : not survived not survived   \n",
      "row  58 : not survived not survived   \n",
      "row  59 : not survived not survived   \n",
      "row  60 :     survived survived       \n",
      "row  61 : not survived not survived   \n",
      "row  62 : not survived not survived   \n",
      "row  63 :     survived not survived   incorrect\n",
      "row  64 : not survived not survived   \n",
      "row  65 : not survived not survived   \n",
      "row  66 : not survived not survived   \n",
      "row  67 : not survived not survived   \n",
      "row  68 : not survived not survived   \n",
      "row  69 : not survived not survived   \n",
      "row  70 :     survived survived       \n",
      "row  71 : not survived not survived   \n",
      "row  72 : not survived not survived   \n",
      "row  73 : not survived not survived   \n",
      "row  74 : not survived not survived   \n",
      "row  75 : not survived not survived   \n",
      "row  76 : not survived not survived   \n",
      "row  77 : not survived not survived   \n",
      "row  78 : not survived survived       incorrect\n",
      "row  79 :     survived not survived   incorrect\n",
      "row  80 : not survived not survived   \n",
      "row  81 : not survived not survived   \n",
      "row  82 :     survived survived       \n",
      "row  83 : not survived survived       incorrect\n",
      "row  84 : not survived not survived   \n",
      "row  85 : not survived not survived   \n",
      "row  86 : not survived not survived   \n",
      "row  87 :     survived survived       \n",
      "row  88 : not survived survived       incorrect\n",
      "row  89 : not survived survived       incorrect\n",
      "row  90 :     survived not survived   incorrect\n",
      "row  91 : not survived not survived   \n",
      "row  92 : not survived survived       incorrect\n",
      "row  93 : not survived survived       incorrect\n",
      "row  94 :     survived not survived   incorrect\n",
      "row  95 : not survived not survived   \n",
      "row  96 : not survived survived       incorrect\n",
      "row  97 : not survived not survived   \n",
      "row  98 : not survived not survived   \n",
      "row  99 : not survived not survived   \n",
      "row 100 :     survived not survived   incorrect\n",
      "row 101 :     survived survived       \n",
      "row 102 : not survived not survived   \n",
      "row 103 :     survived not survived   incorrect\n",
      "row 104 : not survived survived       incorrect\n",
      "row 105 : not survived not survived   \n",
      "row 106 :     survived survived       \n",
      "row 107 : not survived not survived   \n",
      "row 108 : not survived not survived   \n",
      "row 109 :     survived survived       \n",
      "row 110 :     survived survived       \n",
      "row 111 :     survived survived       \n",
      "row 112 : not survived not survived   \n",
      "row 113 : not survived not survived   \n",
      "row 114 :     survived survived       \n",
      "row 115 :     survived survived       \n",
      "row 116 : not survived survived       incorrect\n",
      "row 117 :     survived survived       \n",
      "row 118 : not survived not survived   \n",
      "row 119 : not survived not survived   \n",
      "row 120 : not survived not survived   \n",
      "row 121 :     survived survived       \n",
      "row 122 : not survived not survived   \n",
      "row 123 :     survived survived       \n",
      "row 124 : not survived not survived   \n",
      "row 125 : not survived survived       incorrect\n",
      "row 126 : not survived not survived   \n",
      "row 127 :     survived not survived   incorrect\n",
      "row 128 :     survived survived       \n",
      "row 129 : not survived not survived   \n",
      "row 130 :     survived not survived   incorrect\n",
      "row 131 : not survived not survived   \n",
      "row 132 : not survived not survived   \n",
      "row 133 :     survived survived       \n",
      "row 134 : not survived not survived   \n",
      "row 135 :     survived survived       \n",
      "row 136 : not survived not survived   \n",
      "row 137 : not survived not survived   \n",
      "row 138 :     survived survived       \n",
      "row 139 : not survived not survived   \n",
      "row 140 :     survived survived       \n",
      "row 141 :     survived survived       \n",
      "row 142 :     survived survived       \n",
      "row 143 :     survived survived       \n",
      "row 144 : not survived not survived   \n",
      "row 145 : not survived not survived   \n",
      "row 146 : not survived not survived   \n",
      "row 147 :     survived survived       \n",
      "row 148 : not survived not survived   \n",
      "row 149 : not survived survived       incorrect\n",
      "row 150 : not survived not survived   \n",
      "row 151 : not survived survived       incorrect\n",
      "row 152 :     survived survived       \n",
      "row 153 : not survived not survived   \n",
      "row 154 : not survived not survived   \n",
      "row 155 :     survived survived       \n",
      "row 156 : not survived survived       incorrect\n",
      "row 157 : not survived survived       incorrect\n",
      "row 158 : not survived not survived   \n",
      "row 159 : not survived not survived   \n",
      "row 160 :     survived survived       \n",
      "row 161 : not survived not survived   \n",
      "row 162 :     survived not survived   incorrect\n",
      "row 163 : not survived not survived   \n",
      "row 164 : not survived not survived   \n",
      "row 165 :     survived not survived   incorrect\n",
      "row 166 : not survived not survived   \n",
      "row 167 :     survived survived       \n",
      "row 168 : not survived not survived   \n",
      "row 169 : not survived not survived   \n",
      "row 170 : not survived not survived   \n",
      "row 171 : not survived not survived   \n",
      "row 172 :     survived not survived   incorrect\n",
      "row 173 : not survived not survived   \n",
      "row 174 :     survived survived       \n",
      "row 175 :     survived not survived   incorrect\n",
      "row 176 :     survived survived       \n",
      "row 177 : not survived survived       incorrect\n",
      "row 178 :     survived not survived   incorrect\n",
      "row 179 :     survived survived       \n",
      "row 180 :     survived survived       \n",
      "row 181 :     survived not survived   incorrect\n",
      "row 182 : not survived not survived   \n",
      "row 183 : not survived not survived   \n",
      "row 184 :     survived survived       \n",
      "row 185 :     survived survived       \n",
      "row 186 : not survived survived       incorrect\n",
      "row 187 : not survived not survived   \n",
      "row 188 : not survived not survived   \n",
      "row 189 : not survived not survived   \n",
      "row 190 : not survived not survived   \n",
      "row 191 : not survived not survived   \n",
      "row 192 : not survived not survived   \n",
      "row 193 :     survived not survived   incorrect\n",
      "row 194 :     survived not survived   incorrect\n",
      "row 195 :     survived survived       \n",
      "row 196 :     survived survived       \n",
      "row 197 :     survived survived       \n",
      "row 198 : not survived not survived   \n",
      "row 199 : not survived not survived   \n",
      "\n",
      "Correct: 160 out of 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set!\n",
    "predicted_labels = dtree_model.predict(x_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")\n",
    "\n",
    "# and, let's print our table, too...\n",
    "compare_labels(predicted_labels, actual_labels)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed, as long as compare_labels is set ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'sex', 'age', 'sibsp', 'parch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file tree_depth_1.gv written. Try copying the result to http://viz-js.com/ \n",
      "\n",
      "digraph Tree {\n",
      "node [shape=box, style=\"filled\", color=\"black\"] ;\n",
      "graph [ranksep=equally, splines=polyline] ;\n",
      "0 [label=\"sex <= 0.5\\ngini = 0.485\\nsamples = 804\\nvalue = [471, 333]\\nclass = not survived\", fillcolor=\"#f7dac5\"] ;\n",
      "1 [label=\"gini = 0.339\\nsamples = 505\\nvalue = [396, 109]\\nclass = not survived\", fillcolor=\"#eca46f\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"gini = 0.376\\nsamples = 299\\nvalue = [75, 224]\\nclass = survived\", fillcolor=\"#7bbeee\"] ;\n",
      "0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "{rank=same ; 0} ;\n",
      "{rank=same ; 1; 2} ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's see the tree!\n",
    "#\n",
    "\n",
    "filename = 'tree_depth_' + str(best_depth) + '.gv'  # preferred over .dot\n",
    "\n",
    "tree.export_graphviz(dtree_model, out_file=filename,  # the filename constructed above...!\n",
    "                            feature_names=COLUMNS, # actual feature names, not species\n",
    "                            filled=True,              # fun!\n",
    "                            rotate=False,             # False for Up/Down; True for L/R\n",
    "                            class_names=SPECIES,      # good to have   \n",
    "                            leaves_parallel=True )    # lots of options!\n",
    "\n",
    "print(f\"file {filename} written. Try copying the result to http://viz-js.com/ \\n\")\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    file_text = f.read()\n",
    "    print(file_text)\n",
    "    \n",
    "#\n",
    "# Lab task:  build three trees at depths 1, 2, and 3 (submit with the notebooks!)\n",
    "#\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed, as long as you have SPECIES ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now, to TUNE the model (with cross-validation)...\n",
    "#\n",
    "#\n",
    "# We used a depth of 1    (only 1 split) \n",
    "# There's no way to model three species with only 1 split!\n",
    "#\n",
    "# So, we try several depths...\n",
    "# Here, the tradeoff is not so much \"more accurate\" \n",
    "#       + deeper always has the potential to be more accurate\n",
    "#       + at the risk of overfitting the training data!\n",
    "#\n",
    "# Rather it's the underfitting(bias)/overfitting(variance) tradeoff\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1  cv accuracy:  0.7711\n",
      "depth:  2  cv accuracy:  0.7736\n",
      "depth:  3  cv accuracy:  0.7699\n",
      "depth:  4  cv accuracy:  0.7761\n",
      "depth:  5  cv accuracy:  0.7823\n",
      "depth:  6  cv accuracy:  0.7724\n",
      "depth:  7  cv accuracy:  0.7649\n",
      "depth:  8  cv accuracy:  0.7450\n",
      "depth:  9  cv accuracy:  0.7475\n",
      "depth: 10  cv accuracy:  0.7450\n",
      "\n",
      "best_depth = 5 is our choice for underfitting/overfitting balance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# So, to compare different depths, let's use cross validation\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "\n",
    "best_accuracy = 0\n",
    "for d in range(1, 11):\n",
    "    cv_model = tree.DecisionTreeClassifier(max_depth=d)   # for each depth, d\n",
    "    cv_scores = cross_val_score( cv_model, x_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "    # print(cv_scores)  # if we want to see the five individual scores \n",
    "    average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_depth = d\n",
    "    print(f\"depth: {d:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of d to best_depth \n",
    "print()\n",
    "print(f\"best_depth = {best_depth} is our choice for underfitting/overfitting balance.\")  \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a DT classifier with max depth = 5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "# Now, using the tuned value...\n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_tuned = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_tuned.fit(x_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a DT classifier with max depth =\", best_depth) \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "Actual labels: [1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "\n",
      "row   0 :     survived survived       \n",
      "row   1 : not survived not survived   \n",
      "row   2 : not survived not survived   \n",
      "row   3 :     survived survived       \n",
      "row   4 : not survived not survived   \n",
      "row   5 : not survived not survived   \n",
      "row   6 :     survived survived       \n",
      "row   7 : not survived survived       incorrect\n",
      "row   8 : not survived not survived   \n",
      "row   9 : not survived not survived   \n",
      "row  10 :     survived survived       \n",
      "row  11 :     survived survived       \n",
      "row  12 : not survived not survived   \n",
      "row  13 :     survived not survived   incorrect\n",
      "row  14 : not survived not survived   \n",
      "row  15 :     survived survived       \n",
      "row  16 : not survived not survived   \n",
      "row  17 :     survived survived       \n",
      "row  18 : not survived not survived   \n",
      "row  19 :     survived survived       \n",
      "row  20 : not survived not survived   \n",
      "row  21 : not survived not survived   \n",
      "row  22 : not survived not survived   \n",
      "row  23 : not survived survived       incorrect\n",
      "row  24 :     survived survived       \n",
      "row  25 : not survived not survived   \n",
      "row  26 : not survived survived       incorrect\n",
      "row  27 :     survived survived       \n",
      "row  28 : not survived not survived   \n",
      "row  29 : not survived not survived   \n",
      "row  30 : not survived not survived   \n",
      "row  31 : not survived not survived   \n",
      "row  32 : not survived survived       incorrect\n",
      "row  33 : not survived not survived   \n",
      "row  34 :     survived survived       \n",
      "row  35 :     survived survived       \n",
      "row  36 : not survived not survived   \n",
      "row  37 :     survived survived       \n",
      "row  38 : not survived not survived   \n",
      "row  39 : not survived not survived   \n",
      "row  40 :     survived survived       \n",
      "row  41 : not survived not survived   \n",
      "row  42 : not survived not survived   \n",
      "row  43 : not survived not survived   \n",
      "row  44 : not survived survived       incorrect\n",
      "row  45 : not survived not survived   \n",
      "row  46 : not survived not survived   \n",
      "row  47 : not survived not survived   \n",
      "row  48 : not survived not survived   \n",
      "row  49 :     survived survived       \n",
      "row  50 : not survived not survived   \n",
      "row  51 : not survived not survived   \n",
      "row  52 :     survived not survived   incorrect\n",
      "row  53 : not survived not survived   \n",
      "row  54 : not survived not survived   \n",
      "row  55 : not survived not survived   \n",
      "row  56 :     survived survived       \n",
      "row  57 : not survived not survived   \n",
      "row  58 : not survived not survived   \n",
      "row  59 : not survived not survived   \n",
      "row  60 :     survived survived       \n",
      "row  61 : not survived not survived   \n",
      "row  62 : not survived not survived   \n",
      "row  63 : not survived not survived   \n",
      "row  64 : not survived not survived   \n",
      "row  65 : not survived not survived   \n",
      "row  66 : not survived not survived   \n",
      "row  67 : not survived not survived   \n",
      "row  68 : not survived not survived   \n",
      "row  69 : not survived not survived   \n",
      "row  70 : not survived survived       incorrect\n",
      "row  71 : not survived not survived   \n",
      "row  72 : not survived not survived   \n",
      "row  73 : not survived not survived   \n",
      "row  74 :     survived not survived   incorrect\n",
      "row  75 : not survived not survived   \n",
      "row  76 : not survived not survived   \n",
      "row  77 : not survived not survived   \n",
      "row  78 : not survived survived       incorrect\n",
      "row  79 :     survived not survived   incorrect\n",
      "row  80 : not survived not survived   \n",
      "row  81 : not survived not survived   \n",
      "row  82 :     survived survived       \n",
      "row  83 : not survived survived       incorrect\n",
      "row  84 : not survived not survived   \n",
      "row  85 : not survived not survived   \n",
      "row  86 : not survived not survived   \n",
      "row  87 :     survived survived       \n",
      "row  88 : not survived survived       incorrect\n",
      "row  89 : not survived survived       incorrect\n",
      "row  90 :     survived not survived   incorrect\n",
      "row  91 : not survived not survived   \n",
      "row  92 : not survived survived       incorrect\n",
      "row  93 : not survived survived       incorrect\n",
      "row  94 :     survived not survived   incorrect\n",
      "row  95 : not survived not survived   \n",
      "row  96 :     survived survived       \n",
      "row  97 : not survived not survived   \n",
      "row  98 : not survived not survived   \n",
      "row  99 : not survived not survived   \n",
      "row 100 :     survived not survived   incorrect\n",
      "row 101 : not survived survived       incorrect\n",
      "row 102 : not survived not survived   \n",
      "row 103 : not survived not survived   \n",
      "row 104 : not survived survived       incorrect\n",
      "row 105 : not survived not survived   \n",
      "row 106 :     survived survived       \n",
      "row 107 : not survived not survived   \n",
      "row 108 : not survived not survived   \n",
      "row 109 :     survived survived       \n",
      "row 110 :     survived survived       \n",
      "row 111 :     survived survived       \n",
      "row 112 : not survived not survived   \n",
      "row 113 : not survived not survived   \n",
      "row 114 :     survived survived       \n",
      "row 115 :     survived survived       \n",
      "row 116 : not survived survived       incorrect\n",
      "row 117 :     survived survived       \n",
      "row 118 : not survived not survived   \n",
      "row 119 :     survived not survived   incorrect\n",
      "row 120 : not survived not survived   \n",
      "row 121 :     survived survived       \n",
      "row 122 : not survived not survived   \n",
      "row 123 :     survived survived       \n",
      "row 124 : not survived not survived   \n",
      "row 125 :     survived survived       \n",
      "row 126 : not survived not survived   \n",
      "row 127 : not survived not survived   \n",
      "row 128 :     survived survived       \n",
      "row 129 : not survived not survived   \n",
      "row 130 :     survived not survived   incorrect\n",
      "row 131 : not survived not survived   \n",
      "row 132 : not survived not survived   \n",
      "row 133 :     survived survived       \n",
      "row 134 : not survived not survived   \n",
      "row 135 :     survived survived       \n",
      "row 136 : not survived not survived   \n",
      "row 137 : not survived not survived   \n",
      "row 138 :     survived survived       \n",
      "row 139 : not survived not survived   \n",
      "row 140 :     survived survived       \n",
      "row 141 :     survived survived       \n",
      "row 142 :     survived survived       \n",
      "row 143 :     survived survived       \n",
      "row 144 : not survived not survived   \n",
      "row 145 : not survived not survived   \n",
      "row 146 : not survived not survived   \n",
      "row 147 :     survived survived       \n",
      "row 148 : not survived not survived   \n",
      "row 149 : not survived survived       incorrect\n",
      "row 150 : not survived not survived   \n",
      "row 151 : not survived survived       incorrect\n",
      "row 152 :     survived survived       \n",
      "row 153 : not survived not survived   \n",
      "row 154 : not survived not survived   \n",
      "row 155 :     survived survived       \n",
      "row 156 : not survived survived       incorrect\n",
      "row 157 : not survived survived       incorrect\n",
      "row 158 : not survived not survived   \n",
      "row 159 : not survived not survived   \n",
      "row 160 :     survived survived       \n",
      "row 161 : not survived not survived   \n",
      "row 162 : not survived not survived   \n",
      "row 163 : not survived not survived   \n",
      "row 164 : not survived not survived   \n",
      "row 165 :     survived not survived   incorrect\n",
      "row 166 : not survived not survived   \n",
      "row 167 :     survived survived       \n",
      "row 168 : not survived not survived   \n",
      "row 169 : not survived not survived   \n",
      "row 170 : not survived not survived   \n",
      "row 171 : not survived not survived   \n",
      "row 172 :     survived not survived   incorrect\n",
      "row 173 : not survived not survived   \n",
      "row 174 :     survived survived       \n",
      "row 175 :     survived not survived   incorrect\n",
      "row 176 :     survived survived       \n",
      "row 177 : not survived survived       incorrect\n",
      "row 178 : not survived not survived   \n",
      "row 179 :     survived survived       \n",
      "row 180 :     survived survived       \n",
      "row 181 : not survived not survived   \n",
      "row 182 : not survived not survived   \n",
      "row 183 : not survived not survived   \n",
      "row 184 :     survived survived       \n",
      "row 185 : not survived survived       incorrect\n",
      "row 186 :     survived survived       \n",
      "row 187 : not survived not survived   \n",
      "row 188 : not survived not survived   \n",
      "row 189 : not survived not survived   \n",
      "row 190 : not survived not survived   \n",
      "row 191 : not survived not survived   \n",
      "row 192 : not survived not survived   \n",
      "row 193 :     survived not survived   incorrect\n",
      "row 194 :     survived not survived   incorrect\n",
      "row 195 :     survived survived       \n",
      "row 196 :     survived survived       \n",
      "row 197 :     survived survived       \n",
      "row 198 : not survived not survived   \n",
      "row 199 : not survived not survived   \n",
      "\n",
      "Correct: 165 out of 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = dtree_model_tuned.predict(x_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "print()\n",
    "\n",
    "# and, we'll print our nicer table...\n",
    "compare_labels(predicted_labels,actual_labels)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a 'final' DT classifier with max depth = 5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our DT to use the \"best\" depth...\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_final = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_final.fit(x_all, y_all)                              # yay!  trained!\n",
    "print(\"Created and trained a 'final' DT classifier with max depth =\", best_depth) \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict not survived (0) from Features [1, 0, 63, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# final predictive model (k-nearest-neighbor), with tuned k + ALL data incorporated\n",
    "#\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = dtree_model_final.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    name = SPECIES[predicted_species]\n",
    "#    convert_species(speciesname)\n",
    "    return f\"{name} ({predicted_species})\"\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "\n",
    "Features = [1, 0, 63, 1, 0]\n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")\n",
    "\n",
    "# [[ for hw5pr1's conversion:  need to change to allow the right inputs! ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict not survived (0) from Features [1, 0, 63, 1, 0]\n",
      "I predict survived (1) from Features [1, 1, 39, 0, 0]\n",
      "I predict not survived (0) from Features [1, 0, 53, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# try it on new, \"unseen\" data!\n",
    "#\n",
    "\n",
    "# Less unseen than in hw4, admittedly!\n",
    "\n",
    "LoF = [[1, 0, 63, 1, 0], [1, 1, 39, 0, 0], [1, 0, 53, 2, 0]]\n",
    "for Features in LoF:\n",
    "    result = predictive_model( Features )\n",
    "    print(f\"I predict {result} from Features {Features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# That's it!  Welcome to the world of Decision-Tree models!    \n",
    "#\n",
    "\n",
    "#\n",
    "# But wait, there's more!  More workflows, and more trees!  Random Forests next:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Random Forests!!!\n",
    "#\n",
    "\n",
    "# Lots of trees, each using a partial fraction of the data\n",
    "#      that get together to vote on the correct classification..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF with depth=4 and #trees=42\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-building and Model-training Cell\"\n",
    "#       \n",
    "# Create a RF model and train it! \n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "from sklearn import ensemble  # for random forests\n",
    "\n",
    "best_depth = 4       # we don't know what depth to use, so we guess...\n",
    "best_num_trees = 42   # again, we guess\n",
    "rforest_model = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model.fit(x_train, y_train)                              # yay!  trained!\n",
    "print(f\"Built an RF with depth={best_depth} and #trees={best_num_trees}\") \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "Actual  labels  : [1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "\n",
      "Results on test set:  167 correct out of 200 total.\n",
      "row   0 :     survived survived       \n",
      "row   1 : not survived not survived   \n",
      "row   2 : not survived not survived   \n",
      "row   3 :     survived survived       \n",
      "row   4 : not survived not survived   \n",
      "row   5 : not survived not survived   \n",
      "row   6 :     survived survived       \n",
      "row   7 : not survived survived       incorrect\n",
      "row   8 : not survived not survived   \n",
      "row   9 : not survived not survived   \n",
      "row  10 :     survived survived       \n",
      "row  11 : not survived survived       incorrect\n",
      "row  12 : not survived not survived   \n",
      "row  13 :     survived not survived   incorrect\n",
      "row  14 : not survived not survived   \n",
      "row  15 :     survived survived       \n",
      "row  16 : not survived not survived   \n",
      "row  17 :     survived survived       \n",
      "row  18 : not survived not survived   \n",
      "row  19 :     survived survived       \n",
      "row  20 : not survived not survived   \n",
      "row  21 : not survived not survived   \n",
      "row  22 : not survived not survived   \n",
      "row  23 : not survived survived       incorrect\n",
      "row  24 :     survived survived       \n",
      "row  25 : not survived not survived   \n",
      "row  26 : not survived survived       incorrect\n",
      "row  27 : not survived survived       incorrect\n",
      "row  28 : not survived not survived   \n",
      "row  29 : not survived not survived   \n",
      "row  30 : not survived not survived   \n",
      "row  31 : not survived not survived   \n",
      "row  32 :     survived survived       \n",
      "row  33 :     survived not survived   incorrect\n",
      "row  34 :     survived survived       \n",
      "row  35 :     survived survived       \n",
      "row  36 : not survived not survived   \n",
      "row  37 :     survived survived       \n",
      "row  38 : not survived not survived   \n",
      "row  39 : not survived not survived   \n",
      "row  40 :     survived survived       \n",
      "row  41 : not survived not survived   \n",
      "row  42 : not survived not survived   \n",
      "row  43 : not survived not survived   \n",
      "row  44 : not survived survived       incorrect\n",
      "row  45 : not survived not survived   \n",
      "row  46 : not survived not survived   \n",
      "row  47 : not survived not survived   \n",
      "row  48 : not survived not survived   \n",
      "row  49 :     survived survived       \n",
      "row  50 : not survived not survived   \n",
      "row  51 : not survived not survived   \n",
      "row  52 : not survived not survived   \n",
      "row  53 : not survived not survived   \n",
      "row  54 : not survived not survived   \n",
      "row  55 : not survived not survived   \n",
      "row  56 :     survived survived       \n",
      "row  57 : not survived not survived   \n",
      "row  58 : not survived not survived   \n",
      "row  59 : not survived not survived   \n",
      "row  60 :     survived survived       \n",
      "row  61 : not survived not survived   \n",
      "row  62 : not survived not survived   \n",
      "row  63 : not survived not survived   \n",
      "row  64 : not survived not survived   \n",
      "row  65 : not survived not survived   \n",
      "row  66 : not survived not survived   \n",
      "row  67 : not survived not survived   \n",
      "row  68 : not survived not survived   \n",
      "row  69 : not survived not survived   \n",
      "row  70 : not survived survived       incorrect\n",
      "row  71 : not survived not survived   \n",
      "row  72 : not survived not survived   \n",
      "row  73 : not survived not survived   \n",
      "row  74 : not survived not survived   \n",
      "row  75 : not survived not survived   \n",
      "row  76 : not survived not survived   \n",
      "row  77 : not survived not survived   \n",
      "row  78 : not survived survived       incorrect\n",
      "row  79 :     survived not survived   incorrect\n",
      "row  80 : not survived not survived   \n",
      "row  81 : not survived not survived   \n",
      "row  82 :     survived survived       \n",
      "row  83 : not survived survived       incorrect\n",
      "row  84 : not survived not survived   \n",
      "row  85 : not survived not survived   \n",
      "row  86 : not survived not survived   \n",
      "row  87 :     survived survived       \n",
      "row  88 : not survived survived       incorrect\n",
      "row  89 : not survived survived       incorrect\n",
      "row  90 :     survived not survived   incorrect\n",
      "row  91 : not survived not survived   \n",
      "row  92 : not survived survived       incorrect\n",
      "row  93 : not survived survived       incorrect\n",
      "row  94 :     survived not survived   incorrect\n",
      "row  95 : not survived not survived   \n",
      "row  96 :     survived survived       \n",
      "row  97 : not survived not survived   \n",
      "row  98 : not survived not survived   \n",
      "row  99 : not survived not survived   \n",
      "row 100 :     survived not survived   incorrect\n",
      "row 101 : not survived survived       incorrect\n",
      "row 102 : not survived not survived   \n",
      "row 103 : not survived not survived   \n",
      "row 104 : not survived survived       incorrect\n",
      "row 105 : not survived not survived   \n",
      "row 106 :     survived survived       \n",
      "row 107 : not survived not survived   \n",
      "row 108 : not survived not survived   \n",
      "row 109 :     survived survived       \n",
      "row 110 :     survived survived       \n",
      "row 111 :     survived survived       \n",
      "row 112 : not survived not survived   \n",
      "row 113 : not survived not survived   \n",
      "row 114 :     survived survived       \n",
      "row 115 :     survived survived       \n",
      "row 116 : not survived survived       incorrect\n",
      "row 117 :     survived survived       \n",
      "row 118 : not survived not survived   \n",
      "row 119 : not survived not survived   \n",
      "row 120 : not survived not survived   \n",
      "row 121 :     survived survived       \n",
      "row 122 : not survived not survived   \n",
      "row 123 :     survived survived       \n",
      "row 124 : not survived not survived   \n",
      "row 125 :     survived survived       \n",
      "row 126 : not survived not survived   \n",
      "row 127 : not survived not survived   \n",
      "row 128 :     survived survived       \n",
      "row 129 : not survived not survived   \n",
      "row 130 :     survived not survived   incorrect\n",
      "row 131 : not survived not survived   \n",
      "row 132 : not survived not survived   \n",
      "row 133 :     survived survived       \n",
      "row 134 : not survived not survived   \n",
      "row 135 :     survived survived       \n",
      "row 136 : not survived not survived   \n",
      "row 137 : not survived not survived   \n",
      "row 138 :     survived survived       \n",
      "row 139 : not survived not survived   \n",
      "row 140 :     survived survived       \n",
      "row 141 :     survived survived       \n",
      "row 142 :     survived survived       \n",
      "row 143 :     survived survived       \n",
      "row 144 : not survived not survived   \n",
      "row 145 : not survived not survived   \n",
      "row 146 : not survived not survived   \n",
      "row 147 :     survived survived       \n",
      "row 148 : not survived not survived   \n",
      "row 149 : not survived survived       incorrect\n",
      "row 150 : not survived not survived   \n",
      "row 151 : not survived survived       incorrect\n",
      "row 152 :     survived survived       \n",
      "row 153 : not survived not survived   \n",
      "row 154 : not survived not survived   \n",
      "row 155 :     survived survived       \n",
      "row 156 : not survived survived       incorrect\n",
      "row 157 : not survived survived       incorrect\n",
      "row 158 : not survived not survived   \n",
      "row 159 : not survived not survived   \n",
      "row 160 :     survived survived       \n",
      "row 161 : not survived not survived   \n",
      "row 162 : not survived not survived   \n",
      "row 163 : not survived not survived   \n",
      "row 164 : not survived not survived   \n",
      "row 165 :     survived not survived   incorrect\n",
      "row 166 : not survived not survived   \n",
      "row 167 :     survived survived       \n",
      "row 168 : not survived not survived   \n",
      "row 169 : not survived not survived   \n",
      "row 170 : not survived not survived   \n",
      "row 171 : not survived not survived   \n",
      "row 172 :     survived not survived   incorrect\n",
      "row 173 : not survived not survived   \n",
      "row 174 :     survived survived       \n",
      "row 175 :     survived not survived   incorrect\n",
      "row 176 :     survived survived       \n",
      "row 177 : not survived survived       incorrect\n",
      "row 178 : not survived not survived   \n",
      "row 179 :     survived survived       \n",
      "row 180 :     survived survived       \n",
      "row 181 : not survived not survived   \n",
      "row 182 : not survived not survived   \n",
      "row 183 : not survived not survived   \n",
      "row 184 :     survived survived       \n",
      "row 185 :     survived survived       \n",
      "row 186 :     survived survived       \n",
      "row 187 : not survived not survived   \n",
      "row 188 : not survived not survived   \n",
      "row 189 : not survived not survived   \n",
      "row 190 : not survived not survived   \n",
      "row 191 : not survived not survived   \n",
      "row 192 : not survived not survived   \n",
      "row 193 :     survived not survived   incorrect\n",
      "row 194 :     survived not survived   incorrect\n",
      "row 195 :     survived survived       \n",
      "row 196 :     survived survived       \n",
      "row 197 :     survived survived       \n",
      "row 198 : not survived not survived   \n",
      "row 199 : not survived not survived   \n",
      "\n",
      "Correct: 167 out of 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set!\n",
    "predicted_labels = rforest_model.predict(x_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")\n",
    "\n",
    "# and, let's print our table, too...\n",
    "compare_labels(predicted_labels,actual_labels)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed, if compare_labels is set ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the forest's trees is DecisionTreeClassifier(max_depth=4, max_features='auto',\n",
      "                       random_state=2026695183)\n",
      "file rf_tree_000.gv written. Try copying the result to http://viz-js.com/ \n",
      "\n",
      "digraph Tree {\n",
      "node [shape=box, style=\"filled\", color=\"black\"] ;\n",
      "graph [ranksep=equally, splines=polyline] ;\n",
      "0 [label=\"pclass <= 2.5\\ngini = 0.486\\nsamples = 521\\nvalue = [470, 334]\\nclass = not survived\", fillcolor=\"#f7dbc6\"] ;\n",
      "1 [label=\"sex <= 0.5\\ngini = 0.493\\nsamples = 273\\nvalue = [192, 244]\\nclass = survived\", fillcolor=\"#d5eaf9\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"age <= 12.0\\ngini = 0.377\\nsamples = 152\\nvalue = [178, 60]\\nclass = not survived\", fillcolor=\"#eeab7c\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"gini = 0.0\\nsamples = 5\\nvalue = [0, 8]\\nclass = survived\", fillcolor=\"#399de5\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"age <= 35.5\\ngini = 0.35\\nsamples = 147\\nvalue = [178, 52]\\nclass = not survived\", fillcolor=\"#eda673\"] ;\n",
      "2 -> 4 ;\n",
      "5 [label=\"gini = 0.421\\nsamples = 75\\nvalue = [81, 35]\\nclass = not survived\", fillcolor=\"#f0b78f\"] ;\n",
      "4 -> 5 ;\n",
      "6 [label=\"gini = 0.254\\nsamples = 72\\nvalue = [97, 17]\\nclass = not survived\", fillcolor=\"#ea975c\"] ;\n",
      "4 -> 6 ;\n",
      "7 [label=\"age <= 59.5\\ngini = 0.131\\nsamples = 121\\nvalue = [14, 184]\\nclass = survived\", fillcolor=\"#48a4e7\"] ;\n",
      "1 -> 7 ;\n",
      "8 [label=\"sibsp <= 0.5\\ngini = 0.091\\nsamples = 117\\nvalue = [9, 180]\\nclass = survived\", fillcolor=\"#43a2e6\"] ;\n",
      "7 -> 8 ;\n",
      "9 [label=\"gini = 0.056\\nsamples = 66\\nvalue = [3, 101]\\nclass = survived\", fillcolor=\"#3fa0e6\"] ;\n",
      "8 -> 9 ;\n",
      "10 [label=\"gini = 0.131\\nsamples = 51\\nvalue = [6, 79]\\nclass = survived\", fillcolor=\"#48a4e7\"] ;\n",
      "8 -> 10 ;\n",
      "11 [label=\"age <= 69.5\\ngini = 0.494\\nsamples = 4\\nvalue = [5, 4]\\nclass = not survived\", fillcolor=\"#fae6d7\"] ;\n",
      "7 -> 11 ;\n",
      "12 [label=\"gini = 0.408\\nsamples = 3\\nvalue = [5, 2]\\nclass = not survived\", fillcolor=\"#efb388\"] ;\n",
      "11 -> 12 ;\n",
      "13 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 2]\\nclass = survived\", fillcolor=\"#399de5\"] ;\n",
      "11 -> 13 ;\n",
      "14 [label=\"age <= 16.5\\ngini = 0.37\\nsamples = 248\\nvalue = [278, 90]\\nclass = not survived\", fillcolor=\"#edaa79\"] ;\n",
      "0 -> 14 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "15 [label=\"sibsp <= 2.0\\ngini = 0.49\\nsamples = 40\\nvalue = [40, 30]\\nclass = not survived\", fillcolor=\"#f8e0ce\"] ;\n",
      "14 -> 15 ;\n",
      "16 [label=\"parch <= 1.5\\ngini = 0.42\\nsamples = 26\\nvalue = [12, 28]\\nclass = survived\", fillcolor=\"#8ec7f0\"] ;\n",
      "15 -> 16 ;\n",
      "17 [label=\"gini = 0.36\\nsamples = 22\\nvalue = [8, 26]\\nclass = survived\", fillcolor=\"#76bbed\"] ;\n",
      "16 -> 17 ;\n",
      "18 [label=\"gini = 0.444\\nsamples = 4\\nvalue = [4, 2]\\nclass = not survived\", fillcolor=\"#f2c09c\"] ;\n",
      "16 -> 18 ;\n",
      "19 [label=\"parch <= 1.5\\ngini = 0.124\\nsamples = 14\\nvalue = [28, 2]\\nclass = not survived\", fillcolor=\"#e78a47\"] ;\n",
      "15 -> 19 ;\n",
      "20 [label=\"gini = 0.0\\nsamples = 8\\nvalue = [16, 0]\\nclass = not survived\", fillcolor=\"#e58139\"] ;\n",
      "19 -> 20 ;\n",
      "21 [label=\"gini = 0.245\\nsamples = 6\\nvalue = [12, 2]\\nclass = not survived\", fillcolor=\"#e9965a\"] ;\n",
      "19 -> 21 ;\n",
      "22 [label=\"age <= 21.5\\ngini = 0.322\\nsamples = 208\\nvalue = [238, 60]\\nclass = not survived\", fillcolor=\"#eca16b\"] ;\n",
      "14 -> 22 ;\n",
      "23 [label=\"age <= 20.25\\ngini = 0.202\\nsamples = 54\\nvalue = [70, 9]\\nclass = not survived\", fillcolor=\"#e89152\"] ;\n",
      "22 -> 23 ;\n",
      "24 [label=\"gini = 0.254\\nsamples = 36\\nvalue = [40, 7]\\nclass = not survived\", fillcolor=\"#ea975c\"] ;\n",
      "23 -> 24 ;\n",
      "25 [label=\"gini = 0.117\\nsamples = 18\\nvalue = [30, 2]\\nclass = not survived\", fillcolor=\"#e78946\"] ;\n",
      "23 -> 25 ;\n",
      "26 [label=\"age <= 23.25\\ngini = 0.357\\nsamples = 154\\nvalue = [168, 51]\\nclass = not survived\", fillcolor=\"#eda775\"] ;\n",
      "22 -> 26 ;\n",
      "27 [label=\"gini = 0.487\\nsamples = 26\\nvalue = [18, 13]\\nclass = not survived\", fillcolor=\"#f8dcc8\"] ;\n",
      "26 -> 27 ;\n",
      "28 [label=\"gini = 0.323\\nsamples = 128\\nvalue = [150, 38]\\nclass = not survived\", fillcolor=\"#eca16b\"] ;\n",
      "26 -> 28 ;\n",
      "{rank=same ; 0} ;\n",
      "{rank=same ; 1; 14} ;\n",
      "{rank=same ; 2; 7; 15; 22} ;\n",
      "{rank=same ; 4; 8; 11; 16; 19; 23; 26} ;\n",
      "{rank=same ; 3; 5; 6; 9; 10; 12; 13; 17; 18; 20; 21; 24; 25; 27; 28} ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we can get the individual trees, if we want...\n",
    "#\n",
    "i = 0\n",
    "\n",
    "one_rf_tree = rforest_model.estimators_[i]\n",
    "print(f\"One of the forest's trees is {one_rf_tree}\")\n",
    "\n",
    "# From there, it's possible to create a graphical version...\n",
    "filename = f'rf_tree_{i:03d}.gv'    # .gv preferred over .dot\n",
    "tree.export_graphviz(one_rf_tree, out_file=filename,  # the filename constructed above...!\n",
    "                            feature_names=COLUMNS, # actual feature names, not species\n",
    "                            filled=True,              # fun!\n",
    "                            rotate=False,             # False for Up/Down; True for L/R\n",
    "                            class_names=SPECIES,      # good to have   \n",
    "                            leaves_parallel=True )    # lots of options!\n",
    "print(f\"file {filename} written. Try copying the result to http://viz-js.com/ \\n\")\n",
    "with open(filename, \"r\") as f:\n",
    "    file_text = f.read()\n",
    "    print(file_text)\n",
    "    \n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now, to TUNE the model (with cross-validation)...\n",
    "#\n",
    "#\n",
    "# We used a depth of 1  and #trees of 42  \n",
    "#\n",
    "# So, we try several depths and # of trees\n",
    "# \n",
    "# Again, the tradeoff is underfitting/overfitting...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  50 cv accuracy:  0.7636\n",
      "depth:  1 ntrees: 150 cv accuracy:  0.7711\n",
      "depth:  1 ntrees: 250 cv accuracy:  0.7736\n",
      "depth:  2 ntrees:  50 cv accuracy:  0.7860\n",
      "depth:  2 ntrees: 150 cv accuracy:  0.7823\n",
      "depth:  2 ntrees: 250 cv accuracy:  0.7848\n",
      "depth:  3 ntrees:  50 cv accuracy:  0.7798\n",
      "depth:  3 ntrees: 150 cv accuracy:  0.7836\n",
      "depth:  3 ntrees: 250 cv accuracy:  0.7848\n",
      "depth:  4 ntrees:  50 cv accuracy:  0.7923\n",
      "depth:  4 ntrees: 150 cv accuracy:  0.7960\n",
      "depth:  4 ntrees: 250 cv accuracy:  0.7935\n",
      "depth:  5 ntrees:  50 cv accuracy:  0.7923\n",
      "depth:  5 ntrees: 150 cv accuracy:  0.7898\n",
      "depth:  5 ntrees: 250 cv accuracy:  0.7985\n",
      "depth:  6 ntrees:  50 cv accuracy:  0.7923\n",
      "depth:  6 ntrees: 150 cv accuracy:  0.7961\n",
      "depth:  6 ntrees: 250 cv accuracy:  0.7898\n",
      "depth:  7 ntrees:  50 cv accuracy:  0.7873\n",
      "depth:  7 ntrees: 150 cv accuracy:  0.7861\n",
      "depth:  7 ntrees: 250 cv accuracy:  0.7886\n",
      "depth:  8 ntrees:  50 cv accuracy:  0.7824\n",
      "depth:  8 ntrees: 150 cv accuracy:  0.7873\n",
      "depth:  8 ntrees: 250 cv accuracy:  0.7848\n",
      "depth:  9 ntrees:  50 cv accuracy:  0.7737\n",
      "depth:  9 ntrees: 150 cv accuracy:  0.7736\n",
      "depth:  9 ntrees: 250 cv accuracy:  0.7824\n",
      "depth: 10 ntrees:  50 cv accuracy:  0.7786\n",
      "depth: 10 ntrees: 150 cv accuracy:  0.7736\n",
      "depth: 10 ntrees: 250 cv accuracy:  0.7711\n",
      "\n",
      "best_depth: 5 and best_num_trees: 250 are our choices.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# So, to compare different parameters, let's use cv\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "\n",
    "#\n",
    "# lab task:  wrap this loop in another one! (or create an inner one...)\n",
    "#\n",
    "\n",
    "ntrees = 50   # range(50,300,100)\n",
    "\n",
    "for d in range(1, 11):\n",
    "    for ntrees in range(50,300,100):\n",
    "        rforest_model = ensemble.RandomForestClassifier(max_depth=d, \n",
    "                                                        n_estimators=ntrees)\n",
    "        cv_scores = cross_val_score( rforest_model, x_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "        # print(cv_scores)  # if we want to see the five individual scores \n",
    "        average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "        if average_cv_accuracy > best_accuracy:\n",
    "            best_accuracy = average_cv_accuracy\n",
    "            best_depth = d\n",
    "            best_num_trees = ntrees\n",
    "    \n",
    "        print(f\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    \n",
    "\n",
    "# assign best values\n",
    "print()\n",
    "print(f\"best_depth: {best_depth} and best_num_trees: {best_num_trees} are our choices.\")  \n",
    "\n",
    "#\n",
    "# remember that the lab task is to complete this two-dimensional cv loop!\n",
    "#\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF classifier with depth=5 and ntrees=250\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "from sklearn import ensemble  # for random forests\n",
    "\n",
    "# we should have best_depth and best_num_trees\n",
    "rforest_model_tuned = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                      n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model_tuned.fit(x_train, y_train)                              # yay!  trained!\n",
    "print(f\"Built an RF classifier with depth={best_depth} and ntrees={best_num_trees}\") \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Actual  labels  : [1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "\n",
      "Results on test set:  171 correct out of 200 total.\n",
      "row   0 :     survived survived       \n",
      "row   1 : not survived not survived   \n",
      "row   2 : not survived not survived   \n",
      "row   3 :     survived survived       \n",
      "row   4 : not survived not survived   \n",
      "row   5 : not survived not survived   \n",
      "row   6 :     survived survived       \n",
      "row   7 : not survived survived       incorrect\n",
      "row   8 : not survived not survived   \n",
      "row   9 : not survived not survived   \n",
      "row  10 :     survived survived       \n",
      "row  11 :     survived survived       \n",
      "row  12 : not survived not survived   \n",
      "row  13 :     survived not survived   incorrect\n",
      "row  14 : not survived not survived   \n",
      "row  15 :     survived survived       \n",
      "row  16 : not survived not survived   \n",
      "row  17 : not survived survived       incorrect\n",
      "row  18 : not survived not survived   \n",
      "row  19 :     survived survived       \n",
      "row  20 : not survived not survived   \n",
      "row  21 : not survived not survived   \n",
      "row  22 : not survived not survived   \n",
      "row  23 : not survived survived       incorrect\n",
      "row  24 :     survived survived       \n",
      "row  25 : not survived not survived   \n",
      "row  26 : not survived survived       incorrect\n",
      "row  27 : not survived survived       incorrect\n",
      "row  28 : not survived not survived   \n",
      "row  29 : not survived not survived   \n",
      "row  30 : not survived not survived   \n",
      "row  31 : not survived not survived   \n",
      "row  32 :     survived survived       \n",
      "row  33 : not survived not survived   \n",
      "row  34 :     survived survived       \n",
      "row  35 :     survived survived       \n",
      "row  36 : not survived not survived   \n",
      "row  37 :     survived survived       \n",
      "row  38 : not survived not survived   \n",
      "row  39 : not survived not survived   \n",
      "row  40 :     survived survived       \n",
      "row  41 : not survived not survived   \n",
      "row  42 : not survived not survived   \n",
      "row  43 : not survived not survived   \n",
      "row  44 : not survived survived       incorrect\n",
      "row  45 : not survived not survived   \n",
      "row  46 : not survived not survived   \n",
      "row  47 : not survived not survived   \n",
      "row  48 : not survived not survived   \n",
      "row  49 :     survived survived       \n",
      "row  50 : not survived not survived   \n",
      "row  51 : not survived not survived   \n",
      "row  52 : not survived not survived   \n",
      "row  53 : not survived not survived   \n",
      "row  54 : not survived not survived   \n",
      "row  55 : not survived not survived   \n",
      "row  56 :     survived survived       \n",
      "row  57 : not survived not survived   \n",
      "row  58 : not survived not survived   \n",
      "row  59 : not survived not survived   \n",
      "row  60 :     survived survived       \n",
      "row  61 : not survived not survived   \n",
      "row  62 : not survived not survived   \n",
      "row  63 : not survived not survived   \n",
      "row  64 : not survived not survived   \n",
      "row  65 : not survived not survived   \n",
      "row  66 : not survived not survived   \n",
      "row  67 : not survived not survived   \n",
      "row  68 : not survived not survived   \n",
      "row  69 : not survived not survived   \n",
      "row  70 : not survived survived       incorrect\n",
      "row  71 : not survived not survived   \n",
      "row  72 : not survived not survived   \n",
      "row  73 : not survived not survived   \n",
      "row  74 : not survived not survived   \n",
      "row  75 : not survived not survived   \n",
      "row  76 : not survived not survived   \n",
      "row  77 : not survived not survived   \n",
      "row  78 : not survived survived       incorrect\n",
      "row  79 : not survived not survived   \n",
      "row  80 : not survived not survived   \n",
      "row  81 : not survived not survived   \n",
      "row  82 :     survived survived       \n",
      "row  83 : not survived survived       incorrect\n",
      "row  84 : not survived not survived   \n",
      "row  85 : not survived not survived   \n",
      "row  86 : not survived not survived   \n",
      "row  87 :     survived survived       \n",
      "row  88 : not survived survived       incorrect\n",
      "row  89 : not survived survived       incorrect\n",
      "row  90 :     survived not survived   incorrect\n",
      "row  91 : not survived not survived   \n",
      "row  92 : not survived survived       incorrect\n",
      "row  93 : not survived survived       incorrect\n",
      "row  94 : not survived not survived   \n",
      "row  95 : not survived not survived   \n",
      "row  96 :     survived survived       \n",
      "row  97 : not survived not survived   \n",
      "row  98 : not survived not survived   \n",
      "row  99 : not survived not survived   \n",
      "row 100 :     survived not survived   incorrect\n",
      "row 101 : not survived survived       incorrect\n",
      "row 102 : not survived not survived   \n",
      "row 103 : not survived not survived   \n",
      "row 104 : not survived survived       incorrect\n",
      "row 105 : not survived not survived   \n",
      "row 106 :     survived survived       \n",
      "row 107 : not survived not survived   \n",
      "row 108 : not survived not survived   \n",
      "row 109 :     survived survived       \n",
      "row 110 :     survived survived       \n",
      "row 111 :     survived survived       \n",
      "row 112 : not survived not survived   \n",
      "row 113 : not survived not survived   \n",
      "row 114 :     survived survived       \n",
      "row 115 :     survived survived       \n",
      "row 116 : not survived survived       incorrect\n",
      "row 117 :     survived survived       \n",
      "row 118 : not survived not survived   \n",
      "row 119 : not survived not survived   \n",
      "row 120 : not survived not survived   \n",
      "row 121 :     survived survived       \n",
      "row 122 : not survived not survived   \n",
      "row 123 :     survived survived       \n",
      "row 124 : not survived not survived   \n",
      "row 125 :     survived survived       \n",
      "row 126 : not survived not survived   \n",
      "row 127 : not survived not survived   \n",
      "row 128 :     survived survived       \n",
      "row 129 : not survived not survived   \n",
      "row 130 :     survived not survived   incorrect\n",
      "row 131 : not survived not survived   \n",
      "row 132 : not survived not survived   \n",
      "row 133 :     survived survived       \n",
      "row 134 : not survived not survived   \n",
      "row 135 :     survived survived       \n",
      "row 136 : not survived not survived   \n",
      "row 137 : not survived not survived   \n",
      "row 138 :     survived survived       \n",
      "row 139 : not survived not survived   \n",
      "row 140 :     survived survived       \n",
      "row 141 :     survived survived       \n",
      "row 142 :     survived survived       \n",
      "row 143 :     survived survived       \n",
      "row 144 : not survived not survived   \n",
      "row 145 : not survived not survived   \n",
      "row 146 : not survived not survived   \n",
      "row 147 :     survived survived       \n",
      "row 148 : not survived not survived   \n",
      "row 149 : not survived survived       incorrect\n",
      "row 150 : not survived not survived   \n",
      "row 151 : not survived survived       incorrect\n",
      "row 152 :     survived survived       \n",
      "row 153 : not survived not survived   \n",
      "row 154 : not survived not survived   \n",
      "row 155 :     survived survived       \n",
      "row 156 : not survived survived       incorrect\n",
      "row 157 : not survived survived       incorrect\n",
      "row 158 : not survived not survived   \n",
      "row 159 : not survived not survived   \n",
      "row 160 :     survived survived       \n",
      "row 161 : not survived not survived   \n",
      "row 162 : not survived not survived   \n",
      "row 163 : not survived not survived   \n",
      "row 164 : not survived not survived   \n",
      "row 165 : not survived not survived   \n",
      "row 166 : not survived not survived   \n",
      "row 167 :     survived survived       \n",
      "row 168 : not survived not survived   \n",
      "row 169 : not survived not survived   \n",
      "row 170 : not survived not survived   \n",
      "row 171 : not survived not survived   \n",
      "row 172 :     survived not survived   incorrect\n",
      "row 173 : not survived not survived   \n",
      "row 174 : not survived survived       incorrect\n",
      "row 175 :     survived not survived   incorrect\n",
      "row 176 :     survived survived       \n",
      "row 177 : not survived survived       incorrect\n",
      "row 178 : not survived not survived   \n",
      "row 179 :     survived survived       \n",
      "row 180 :     survived survived       \n",
      "row 181 : not survived not survived   \n",
      "row 182 : not survived not survived   \n",
      "row 183 : not survived not survived   \n",
      "row 184 :     survived survived       \n",
      "row 185 :     survived survived       \n",
      "row 186 :     survived survived       \n",
      "row 187 : not survived not survived   \n",
      "row 188 : not survived not survived   \n",
      "row 189 : not survived not survived   \n",
      "row 190 : not survived not survived   \n",
      "row 191 : not survived not survived   \n",
      "row 192 : not survived not survived   \n",
      "row 193 : not survived not survived   \n",
      "row 194 :     survived not survived   incorrect\n",
      "row 195 :     survived survived       \n",
      "row 196 :     survived survived       \n",
      "row 197 :     survived survived       \n",
      "row 198 : not survived not survived   \n",
      "row 199 : not survived not survived   \n",
      "\n",
      "Correct: 171 out of 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# +++ This is our \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set!\n",
    "predicted_labels = rforest_model_tuned.predict(x_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")\n",
    "\n",
    "# and, let's print our table, too...\n",
    "compare_labels(predicted_labels,actual_labels)\n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF classifier with depth=5 and ntrees=250\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our RF to use the \"best\" parameters\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "from sklearn import ensemble  # for random forests\n",
    "\n",
    "# we should have best_depth and best_num_trees\n",
    "rforest_model_final = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                      n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model_final.fit(x_all, y_all)              # yay!  trained!\n",
    "print(f\"Built an RF classifier with depth={best_depth} and ntrees={best_num_trees}\") \n",
    "\n",
    "# [[ for hw5pr1's conversion:  no changes needed ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict not survived (0) from Features [1, 0, 63, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# final predictive model (k-nearest-neighbor), with tuned k + ALL data incorporated\n",
    "#\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = rforest_model_final.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    name = SPECIES[predicted_species]\n",
    "    return f\"{name} ({predicted_species})\"\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "Features = [1, 0, 63, 1, 0]\n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")\n",
    "\n",
    "# [[ for hw5pr1's conversion:  need to change to handle the right inputs! ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict not survived (0) from Features [1, 0, 63, 1, 0]\n",
      "I predict survived (1) from Features [1, 1, 39, 0, 0]\n",
      "I predict not survived (0) from Features [1, 0, 53, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# try it on new, \"unseen\" data!\n",
    "#\n",
    "\n",
    "# Less unseen than in hw4, admittedly!\n",
    "\n",
    "LoF = [[1, 0, 63, 1, 0], [1, 1, 39, 0, 0], [1, 0, 53, 2, 0]]\n",
    "      \n",
    "for Features in LoF:\n",
    "    result = predictive_model( Features )\n",
    "    print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21108606 0.53611211 0.13973921 0.05843143 0.0546312 ]\n",
      "\n",
      "Feature       pclass has   21.11% of the decision-making importance.\n",
      "Feature          sex has   53.61% of the decision-making importance.\n",
      "Feature          age has   13.97% of the decision-making importance.\n",
      "Feature        sibsp has    5.84% of the decision-making importance.\n",
      "Feature        parch has    5.46% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# feature importances can be even more \"important\" than predictions!\n",
    "#\n",
    "\n",
    "print(rforest_model_final.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = rforest_model_final.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {COLUMNS[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments: \n",
    "\n",
    "For our decision tree model, we found that our best depth was 5 (of our options) at an accuracy of 0.7823.\n",
    "\n",
    "For our random forest model, we found that a depth of 5 and 250 trees produced the best accuracy (of our options) at 0.7985.\n",
    "\n",
    "When we looked at our kNN in hw4, we found that our previous accuracy was 0.7488 (for k = 7).\n",
    "\n",
    "Look below for the random forest model feature importances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature       pclass has   21.11% of the decision-making importance.\n",
    "Feature          sex has   53.61% of the decision-making importance.\n",
    "Feature          age has   13.97% of the decision-making importance.\n",
    "Feature        sibsp has    5.84% of the decision-making importance.\n",
    "Feature        parch has    5.46% of the decision-making importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.11, 53.61, 13.97, 5.84, 5.46]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import pi\n",
    " \n",
    "# Set data\n",
    "df = pd.DataFrame({\n",
    "'pclass': ['A','B','C','D'],\n",
    "'var1': [38, 1.5, 30, 4],\n",
    "'var2': [29, 10, 9, 34],\n",
    "'var3': [8, 39, 23, 24],\n",
    "'var4': [7, 31, 33, 14],\n",
    "'var5': [28, 15, 32, 14]\n",
    "})\n",
    " \n",
    "# number of variable\n",
    "categories=['pclass', 'sex', 'age', 'sibsp', 'parch']\n",
    "N = len(categories)\n",
    "\n",
    "# We are going to plot the first line of the data frame.\n",
    "# But we need to repeat the first value to close the circular graph:\n",
    "values=[21.11, 53.61, 13.97, 5.84, 5.46]\n",
    "print(values)\n",
    "values += values[:1]\n",
    "values\n",
    " \n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    " \n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    " \n",
    "# Draw one axe per variable + add labels\n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    " \n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([10,20,30,40,50], [\"10\",\"20\",\"30\", \"40\", \"50\"], color=\"grey\", size=7)\n",
    "plt.ylim(0,60)\n",
    " \n",
    "# Plot data\n",
    "ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    " \n",
    "# Fill area\n",
    "ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
